{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN1XGOcusPSmtk2e637koFr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mfierbaugh/asp-ai-lab/blob/main/openai_lab1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This lab is a walk through of how to build your first chatbot using openAI.  "
      ],
      "metadata": {
        "id": "s6FfubnfVVxj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/mfierbaugh/asp-ai-lab.git"
      ],
      "metadata": {
        "id": "o8iUz_T9C5yu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This lab uses openAI's Chat Completion API, so we need to install the libraries into our runtime enviornment."
      ],
      "metadata": {
        "id": "ufpS6c5wVIAD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "collapsed": true,
        "id": "-I01cVVlvFu5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have the openAI libraries installed, we are going to import those libraies into our code so we can use them."
      ],
      "metadata": {
        "id": "neu_OyPPQXjk"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9B-1AfNIVUr6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "CtaDDMWHuCZL"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "from google.colab import userdata"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have the ability to use different models in openAI's API.  Let's create a simple variable and store the model name as a string.  We will pass this to openAI via a function later.  "
      ],
      "metadata": {
        "id": "pLqniy6NuWxU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = \"gpt-3.5-turbo\""
      ],
      "metadata": {
        "id": "YXa8E52A0YEI"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a function in python that will have 3 things passed to it when we call it.  \n",
        "\n",
        "1. The user's question.\n",
        "2. The client - in our case OpenAI with the API key defined.\n",
        "3. The model we want to use.\n",
        "\n",
        "Coding up the function in this way alows for us to change the model or client if we so desire.  \n",
        "\n",
        "This is using OpenAI's Chat Completions API and contains the inputs along with the instructions for providing an output."
      ],
      "metadata": {
        "id": "6YlzCvLY0WM6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def chat_openai (user_question, client, model):\n",
        "    \"\"\"\n",
        "    This function sends a chat message to the OpenAI API and returns the content of the response.\n",
        "    It takes two parameters: the chat prompt and the model to use for the chat.\n",
        "    \"\"\"\n",
        "    prompt = \"\"\"\n",
        "    {user_question}\n",
        "\n",
        "    Analyze the user's question and provide an answer based upon the context of the question.\n",
        "    \"\"\".format(\n",
        "        user_question=user_question\n",
        "    )\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"You are a rude cynical assistant network engineer:\",\n",
        "            },\n",
        "            {\"role\": \"user\", \"content\": prompt},\n",
        "        ],\n",
        "    )\n",
        "    return response.choices[0].message.content"
      ],
      "metadata": {
        "id": "vJhhvdfWuY-s"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Chat Completions API supports text and image inputs, and can output text content (including code and JSON).\n",
        "\n",
        "Let's take a closer look at the prompts.\n",
        "\n",
        "The prompt includes the user question and a set of instructions designed to control the output of the response.  \n",
        "\n",
        "Each message object has a role (either system, user, or assistant) and content.\n",
        "\n",
        "*   The system message is optional and can be used to set the behavior of the assistant\n",
        "*   The user messages provide requests or comments for the assistant to respond to\n",
        "*   Assistant messages store previous assistant responses, but can also be written by you to give examples of desired behavior\n",
        "\n"
      ],
      "metadata": {
        "id": "1Q0Ye5Ksug4_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice above how we have set the behavior of the assistant by telling it \"You are a rude cynical assistant network engineer:\"\n",
        "\n",
        "We are just having some fun here.  We can make the responses come back snarky, just to show how we can change the behavior."
      ],
      "metadata": {
        "id": "vPbQW5JlPqIS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's create a the user's question.  You can change this if you like."
      ],
      "metadata": {
        "id": "hGOQhUgJU5zb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_question = \"Which routers are better, Juniper or Cisco?\""
      ],
      "metadata": {
        "id": "vhkrYEHDPy4-"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, We are going to send the system prompt and the user question to openAI's API using the function we defined above."
      ],
      "metadata": {
        "id": "AMXGjGIgNCyy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "openai_api_key = userdata.get('OPENAI_API_KEY')\n",
        "client = OpenAI(api_key=openai_api_key)\n",
        "\n",
        "response = chat_openai(user_question, client, model)\n",
        "\n",
        "print(response)"
      ],
      "metadata": {
        "id": "UtusEcAlum54",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PENhbEhGC4Vx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}